# Hyperledger Architecture Summary

Full in-depth details can be found on the official documentation at [Hyperledger Architecture Reference](https://hyperledger-fabric.readthedocs.io/en/latest/architecture.html)

## Assets

An **Asset** is the logical representation of a tangible asset (property, hardware, etc...) or intangible asset 
(intellectual property, etc...) on the blockchain.

It is represented as a collection of Key-Value pairs (**KV**).

Smart contracts (**Chaincode**) can modify **Assets** that they have access to.

### Rental Asset

In our case we want to represent **Rental Assets** (room, apartment, house, etc...) on the blockchain.

Possible representation :

In order to reduce the complexity of the *checkAvailability* feature of the **Chaincode**, I thought about representing
available dates as a *single-linked list* of dates, where the first available date links to the furthest available date
without interruption.

*e.g. : MyHome is available from Feb. 2 till March 1 and then again from March 18 till June 10*

But we would still need to return one KV per available date range. Another way would be to have a *single-linked list*
with two kinds of links : *availableTill* and *unavailableTill*. \
Each element can only have one link set at a given time, and in the end the list will be an alternating list of 
*(Date, availableTill)* and *(Date, unavailableTill)*.

This way the **Chaincode** only needs to return the first available date in the range. \
*e.g. : checkAvailability(Jan. 1, May 4) -> (Feb. 2, availableTill_pointer)* \
*e.g. : checkAvailability(March 5, March 23) -> (March 18, availableTill_pointer)*

Representation :
* MyHome :
    * KV0 : Key=Feb. 2 ; Value=availableTill(KV1)
    * KV1 : Key=March 1 ; Value=unavailableTill(KV2)
    * KV2 : Key=March 18 ; Value=availableTill(KV3)
    * KV3 : Key=June 10 ; Value=nil

The rest of the availability-checking logic can be performed on the OTA's side as long as they are up-to date with the
current state of the blockchain (to traverse the list, stopping at the date-range's end if necessary).

In that way, the complexity of *checkAvailability* remains constant on the **Chainode**'s side (return the first
available date in the range or nil).

## The Blockchain

The central component of a Hyperledger Fabric system which records all transactions that happened.

In Fabric it is logically decomposed into two components :
1. the **World State** (or **State**) : the latest state of of the blockchain, represented as a Key-Value Store (KVS) \
(cf. [Architecture Explained - State](https://hyperledger-fabric.readthedocs.io/en/latest/arch-deep-dive.html#state) for more details)
2. the **Ledger** : a verifiable, and immutable history of all successful and unsuccessful changes to the blockchain's **State**
since its genesis. It is represented as a totally ordered hashchain of *blocks*.

### State

The state is a mapping, distributed as a KVS.

The mapping is : `K -> (V x N)` where : \
* `K` is the set of Keys
* `V` is the set of Values
* `N` is an ordered set of version numbers

It is maintained by *peers* but not *orderers* or *clients*.

In our case, the collection of all **Assets** KVs.

### Ledger

It is generated by *orderers* and kept by all *peers* and a subset of *orderers* (chosen to satisfy the properties of
the *ordering service*).

As a historical record of all transactions since genesis it can be used to reconstruct any **State** up-to and including
the current **State**.

## Nodes

There are three types of Nodes :
* Cient
* Peer
* Orderer

### Client Nodes

**Clients** submit the actual *transaction-invocations* to **Chaincode** *endorsers* and broadcast *transaction-proposals*
to the *ordering service* when the endorsers accept it.

In our case most of the transactions are invoked by the OTAs, either directly or as a proxy for Partners. Then it would
seem natural to have **client** nodes reside on the OTA's side. They would be the *interface* between the existing system
and this *blockchain-based* distributed system.

### Peer Nodes

**Peers** commit transactions to the blockchain : they receive **State** updates from the *ordering service* in the form
of blocks and maintain the **State** and the **Ledger**.

**Peers** can have a special role : *endorser*. A **chaincode** can specify an *endorsement policy* to define how to
validate or reject *transaction-invocations* on its operations, this policy refers to a set of *endorser peers* that will
execute this validation logic.

Here we can see a few issues arising :
* If a particular **OTA** has enough **endorsers** running on its network for a particular **chaincode** (i.e. rental asset)
then it could have one of its **client** nodes, trying to invoke a *transaction* on the **chaincode**, be nigh-automatically
endorsed. \
As a result, the rental assets' **chaincode** *endorsement policy* should define a valid endorsement as being delivered
by multiple **OTAs**. The time complexity of the *endorsement* step will then necessarily be bounded by intra-OTA communication
speed.
* If one of a given **OTA**'s **clients** needs to contact other **OTAs**' **endorsers** for an attempted *transaction* \
Therefore not only the validated *transactions* need to meet anonymity criterias when they are appended to the **ledger** but the
*transaction-invocations* must also meet certain anonymity criterias when sent to **endorsers** for validation.

### Orderer Nodes

**Orderer** nodes provide the *ordering service* in Fabric : offering a *shared channel* on which **clients** and **peers**
can communicate. This channel is comparable to a *topic* in a publish-subscribe model. These channels support *total-ordering*
of messages (= *atomic broadcast*).

**Clients** can connect to the channel and broadcast messages to the **peers** that are also connected to it. These messages
are the candidate *transactions* that may be included in the blockchain.

**Clients** and **peers** that are connected to a channel are unaware of other channels and the messages that may be broadcast
on them. Both **client** and **peer** nodes can connect to multiple channels however.

The API exposed by the *ordering service* consists of two functionalities :
* `broadcast(blob)` : called by **clients** to broadcast a message in the form of a *blob* (Binary Large Object)
* `deliver(seqno, prevhash, blob)` : called by the *ordering service* on **peer** nodes (much like RMI ?) in order to deliver
a *blob*. The *sequence number* `seqno` and the hash of the most recently delivered *blob* `prevhash` are used to ensure 
the *total-ordering*.

In practice, *transactions* are appended to the blockchain in the form of *blocks* rather than individually, through a
single `deliver` event. Logically, *blocks* can be thought of as an ordered sequence of individual `deliver` events.

In our case each **asset** would define a new private channel for every **OTA** that is authorized to manage it. While the
*transaction-invocations* themselves are not available to competing **OTAs**, the *checkAvailability* logic is tied to the
current **state** for the **asset** which is publicly available, therefore *overbooking* solution can function. 
